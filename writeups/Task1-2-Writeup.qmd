---
title: "Tasks 1-2 Writeup"
format: html
editor: visual
---

## Task 1

### Question

The driving question for task 1 was to augment the HTML scraping strategy so that header information is captured in addition to paragraph content and check if binary class predictions improved using logistic principal component regression?

### Process

To find out if including headers ended up improving our accuracy we ran two distinct PCA logistic regression models. One where the headers were not included and another where the headers were included. We then computed the accuracies for each of the models and compared them.

### Results

| Including headers         | Not including headers     |
|---------------------------|---------------------------|
| sensitivity binary 0.813  | sensitivity binary 0.842  |
| specificity binary 0.769  | specificity binary 0.740  |
| accuracy binary 0.793     | accuracy binary 0.797     |
| roc_auc binary 0.876      | roc_auc binary 0.857      |

Above are the results for some key metrics between the two models. We can clearly see that in terms of accuracy, the models do not differ nearly at all. There is a .004 difference in accuracy which works out to about .4%, a miniscule amount. Thus, we can say that including the headers does not necessarily increase the binary class predictions for the principal component logistic regression.

## Task 2

### Question

Perform a secondary tokenization of the data to obtain bigrams. Fit a logistic principal component regression model to the word-tokenized data, and then input the predicted log-odds-ratios together with some number of principal components of the bigram-tokenized data to a *second* logistic regression model. Based on the results, does it seem like the bigrams capture additional information about the claims status of a page?

### Process

First we redefined the function that was used for the unigrams to work and create bigrams to be used in the model creation. We then split the data set on an 80% training and 20% testing split. Once split, we made sure to follow the same process that was used for the unigrams. This allowed us to compare them properly at the end.

### Results

| Bigram Accuracy           |
|---------------------------|
| sensitivity binary 0.987  |
| specificity binary 0.0422 |
| accuracy binary 0.589     |
| roc_auc binary 0.750      |

Here, we can see that the binary accuracy comes out to 0.589 or 58.9%. This percentage is not great and definitely lower than the \~70% that the unigrams got for their binary accuracy. Bigrams do not capture additional information about the claims status of a page. This could be due to many reasons such as sparsity of bigram features, overfitting, loss of contextual information, and increased model complexity.
